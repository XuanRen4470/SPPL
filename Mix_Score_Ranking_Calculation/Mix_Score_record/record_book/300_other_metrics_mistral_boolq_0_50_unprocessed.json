{
    "boolq_step_by_step": {
        "perplexity": 4.350439276695251,
        "IDF_score": 0.736,
        "log_propability": -246.0,
        "skywork_reward_score": 7.7725,
        "CAR_score": 1.47
    },
    "boolq_claude": {
        "perplexity": 3.2221533966064455,
        "IDF_score": 0.649,
        "log_propability": -223.0,
        "skywork_reward_score": 8.6402734375,
        "CAR_score": 1.94
    },
    "boolq_gpt4_style_in_context_examples": {
        "perplexity": 4.469725835323334,
        "IDF_score": 0.617,
        "log_propability": -158.0,
        "skywork_reward_score": 8.571328125,
        "CAR_score": 1.64
    },
    "boolq_gpt4": {
        "perplexity": 5.453560135364532,
        "IDF_score": 0.715,
        "log_propability": -166.0,
        "skywork_reward_score": 6.812421875,
        "CAR_score": 1.17
    },
    "boolq_mini_gpt4": {
        "perplexity": 4.861950788497925,
        "IDF_score": 0.701,
        "log_propability": -149.0,
        "skywork_reward_score": 8.0455078125,
        "CAR_score": 1.44
    },
    "boolq_groundtruth": {
        "perplexity": 92523.88521484374,
        "IDF_score": 1.57,
        "log_propability": -16.8,
        "skywork_reward_score": 2.67765625,
        "CAR_score": 0.0784
    },
    "boolq_openai_human_written_examples": {
        "perplexity": 3.634889094829559,
        "IDF_score": 0.518,
        "log_propability": -111.0,
        "skywork_reward_score": 9.6519140625,
        "CAR_score": 2.07
    }
}