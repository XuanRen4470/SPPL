{
    "mmlu_pro_law_step_by_step": {
        "perplexity": 4.616363854408264,
        "IDF_score": 0.806,
        "log_propability": -621.0,
        "skywork_reward_score": 12.303351135253907,
        "CAR_score": 2.23
    },
    "mmlu_pro_law_claude": {
        "perplexity": 3.327394714355469,
        "IDF_score": 0.718,
        "log_propability": -329.0,
        "skywork_reward_score": 9.2066162109375,
        "CAR_score": 2.02
    },
    "mmlu_pro_law_gpt4_style_in_context_examples": {
        "perplexity": 4.976109107732773,
        "IDF_score": 0.78,
        "log_propability": -495.0,
        "skywork_reward_score": 12.865610427856446,
        "CAR_score": 2.25
    },
    "mmlu_pro_law_gpt4": {
        "perplexity": 5.323563709259033,
        "IDF_score": 0.794,
        "log_propability": -433.0,
        "skywork_reward_score": 8.284951171875,
        "CAR_score": 1.41
    },
    "mmlu_pro_law_mini_gpt4": {
        "perplexity": 4.742638657093048,
        "IDF_score": 0.733,
        "log_propability": -351.0,
        "skywork_reward_score": 6.486474609375,
        "CAR_score": 1.16
    },
    "mmlu_pro_law_groundtruth": {
        "perplexity": 23355.93611190796,
        "IDF_score": 1.38,
        "log_propability": -34.9,
        "skywork_reward_score": -13.9815625,
        "CAR_score": -0.515
    },
    "mmlu_pro_law_openai_human_written_examples": {
        "perplexity": 6.397908213138581,
        "IDF_score": 0.765,
        "log_propability": -284.0,
        "skywork_reward_score": 5.98716064453125,
        "CAR_score": 0.942
    }
}