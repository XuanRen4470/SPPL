{
    "plan_bench_generalization_step_by_step": {
        "perplexity": 1.7374817967414855,
        "IDF_score": 0.622,
        "log_propability": -235.0,
        "skywork_reward_score": -1.735546875,
        "CAR_score": -0.663
    },
    "plan_bench_generalization_claude": {
        "perplexity": 2.103380537033081,
        "IDF_score": 0.623,
        "log_propability": -184.0,
        "skywork_reward_score": -4.518359375,
        "CAR_score": -1.41
    },
    "plan_bench_generalization_gpt4_style_in_context_examples": {
        "perplexity": 1.648539674282074,
        "IDF_score": 0.544,
        "log_propability": -199.0,
        "skywork_reward_score": -3.197265625,
        "CAR_score": -1.3
    },
    "plan_bench_generalization_gpt4": {
        "perplexity": 1.9977829098701476,
        "IDF_score": 0.648,
        "log_propability": -238.0,
        "skywork_reward_score": -5.29453125,
        "CAR_score": -1.77
    },
    "plan_bench_generalization_mini_gpt4": {
        "perplexity": 2.08101304769516,
        "IDF_score": 0.675,
        "log_propability": -304.0,
        "skywork_reward_score": -8.030078125,
        "CAR_score": -2.54
    },
    "plan_bench_generalization_groundtruth": {
        "perplexity": 4.104067587852478,
        "IDF_score": 0.621,
        "log_propability": -74.6,
        "skywork_reward_score": -9.18125,
        "CAR_score": -1.85
    },
    "plan_bench_generalization_openai_human_written_examples": {
        "perplexity": 2.052508008480072,
        "IDF_score": 0.613,
        "log_propability": -215.0,
        "skywork_reward_score": -6.026171875,
        "CAR_score": -1.95
    },
    "plan_bench_generalization_rewrite_groundtruth_in_own_words": {
        "perplexity": 2.84270693063736,
        "IDF_score": 0.742,
        "log_propability": -295.0,
        "skywork_reward_score": -14.190625,
        "CAR_score": -3.55
    }
}