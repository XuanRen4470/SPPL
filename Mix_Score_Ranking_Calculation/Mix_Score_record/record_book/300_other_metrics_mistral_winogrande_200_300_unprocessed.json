{
    "winogrande_step_by_step": {
        "perplexity": 4.747660655975341,
        "IDF_score": 0.758,
        "log_propability": -357.0,
        "skywork_reward_score": 11.841796875,
        "CAR_score": 2.12
    },
    "winogrande_claude": {
        "perplexity": 4.24340931892395,
        "IDF_score": 0.676,
        "log_propability": -229.0,
        "skywork_reward_score": 11.24611328125,
        "CAR_score": 2.15
    },
    "winogrande_gpt4_style_in_context_examples": {
        "perplexity": 5.124238594770431,
        "IDF_score": 0.644,
        "log_propability": -212.0,
        "skywork_reward_score": 13.207890625,
        "CAR_score": 2.29
    },
    "winogrande_gpt4": {
        "perplexity": 6.8579983901977535,
        "IDF_score": 0.645,
        "log_propability": -174.0,
        "skywork_reward_score": 10.9016796875,
        "CAR_score": 1.7
    },
    "winogrande_mini_gpt4": {
        "perplexity": 5.6566579937934875,
        "IDF_score": 0.622,
        "log_propability": -179.0,
        "skywork_reward_score": 10.592578125,
        "CAR_score": 1.75
    },
    "winogrande_groundtruth": {
        "perplexity": 63478.155573730466,
        "IDF_score": 2.17,
        "log_propability": -10.3,
        "skywork_reward_score": 4.8938525390625,
        "CAR_score": 0.151
    },
    "winogrande_openai_human_written_examples": {
        "perplexity": 6.417931275367737,
        "IDF_score": 0.538,
        "log_propability": -119.0,
        "skywork_reward_score": 11.409581604003906,
        "CAR_score": 1.83
    }
}