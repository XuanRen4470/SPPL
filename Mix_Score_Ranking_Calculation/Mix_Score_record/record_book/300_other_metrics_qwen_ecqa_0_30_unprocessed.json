{
    "ecqa_step_by_step": {
        "perplexity": 3.354041051864624,
        "IDF_score": 0.747,
        "log_propability": -301.0,
        "skywork_reward_score": 12.458072916666667,
        "CAR_score": 2.71
    },
    "ecqa_claude": {
        "perplexity": 3.0838467200597126,
        "IDF_score": 0.606,
        "log_propability": -186.0,
        "skywork_reward_score": 12.457096354166667,
        "CAR_score": 2.87
    },
    "ecqa_gpt4_style_in_context_examples": {
        "perplexity": 3.4539660453796386,
        "IDF_score": 0.723,
        "log_propability": -315.0,
        "skywork_reward_score": 18.383854166666666,
        "CAR_score": 3.93
    },
    "ecqa_gpt4": {
        "perplexity": 3.739499735832214,
        "IDF_score": 0.648,
        "log_propability": -212.0,
        "skywork_reward_score": 11.448567708333334,
        "CAR_score": 2.37
    },
    "ecqa_mini_gpt4": {
        "perplexity": 3.461606240272522,
        "IDF_score": 0.572,
        "log_propability": -167.0,
        "skywork_reward_score": 7.443489583333333,
        "CAR_score": 1.61
    },
    "ecqa_groundtruth": {
        "perplexity": 35.314602788289385,
        "IDF_score": 0.845,
        "log_propability": -170.0,
        "skywork_reward_score": 1.46357421875,
        "CAR_score": 0.128
    },
    "ecqa_openai_human_written_examples": {
        "perplexity": 3.4066245873769123,
        "IDF_score": 0.565,
        "log_propability": -182.0,
        "skywork_reward_score": 10.83828125,
        "CAR_score": 2.36
    },
    "ecqa_rewrite_groundtruth_in_own_words": {
        "perplexity": 5.293551325798035,
        "IDF_score": 0.532,
        "log_propability": -124.0,
        "skywork_reward_score": 4.788020833333333,
        "CAR_score": 0.818
    }
}