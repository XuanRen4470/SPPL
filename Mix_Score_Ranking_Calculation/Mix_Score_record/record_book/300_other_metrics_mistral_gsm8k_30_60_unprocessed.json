{
    "gsm8k_step_by_step": {
        "perplexity": 1.983226736386617,
        "IDF_score": 0.631,
        "log_propability": -160.0,
        "skywork_reward_score": 12.408854166666666,
        "CAR_score": 4.13
    },
    "gsm8k_claude": {
        "perplexity": 1.9987202008565268,
        "IDF_score": 0.528,
        "log_propability": -104.0,
        "skywork_reward_score": 15.889583333333333,
        "CAR_score": 5.24
    },
    "gsm8k_gpt4_style_in_context_examples": {
        "perplexity": 2.4462942282358804,
        "IDF_score": 0.642,
        "log_propability": -158.0,
        "skywork_reward_score": 7.341796875,
        "CAR_score": 2.05
    },
    "gsm8k_gpt4": {
        "perplexity": 2.2201583623886108,
        "IDF_score": 0.587,
        "log_propability": -132.0,
        "skywork_reward_score": 12.632291666666667,
        "CAR_score": 3.92
    },
    "gsm8k_mini_gpt4": {
        "perplexity": 2.202140764395396,
        "IDF_score": 0.571,
        "log_propability": -136.0,
        "skywork_reward_score": 12.832291666666666,
        "CAR_score": 3.94
    },
    "gsm8k_groundtruth": {
        "perplexity": 5.619742035865784,
        "IDF_score": 0.969,
        "log_propability": -137.0,
        "skywork_reward_score": 2.9813802083333334,
        "CAR_score": 0.544
    },
    "gsm8k_openai_human_written_examples": {
        "perplexity": 2.3873357653617857,
        "IDF_score": 0.579,
        "log_propability": -143.0,
        "skywork_reward_score": 7.156510416666666,
        "CAR_score": 2.05
    },
    "gsm8k_rewrite_groundtruth_in_own_words": {
        "perplexity": 4.52362847328186,
        "IDF_score": 0.783,
        "log_propability": -221.0,
        "skywork_reward_score": -1.7171875,
        "CAR_score": -0.322
    }
}