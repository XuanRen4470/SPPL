{
    "mmlu_moral_scenarios_step_by_step": {
        "perplexity": 3.9119924306869507,
        "diversity_score": 0.0913,
        "complexity_score": 0.0429,
        "IDF_score": 0.545,
        "average_token_len": 274.92,
        "Average_Char_Lenth": 1143.7
    },
    "mmlu_moral_scenarios_gpt4": {
        "perplexity": 4.03369713306427,
        "diversity_score": 0.069,
        "complexity_score": 0.0402,
        "IDF_score": 0.423,
        "average_token_len": 186.54,
        "Average_Char_Lenth": 809.68
    },
    "mmlu_moral_scenarios_claude": {
        "perplexity": 2.919289774894714,
        "diversity_score": 0.0722,
        "complexity_score": 0.0425,
        "IDF_score": 0.401,
        "average_token_len": 189.14,
        "Average_Char_Lenth": 805.56
    },
    "mmlu_moral_scenarios_mini_gpt4": {
        "perplexity": 3.7416307497024537,
        "diversity_score": 0.068,
        "complexity_score": 0.0388,
        "IDF_score": 0.371,
        "average_token_len": 167.72,
        "Average_Char_Lenth": 715.44
    },
    "mmlu_moral_scenarios_groundtruth": {
        "perplexity": 44890.16088623047,
        "diversity_score": 0.362,
        "complexity_score": 0.00215,
        "IDF_score": 72.4,
        "average_token_len": 5.0,
        "Average_Char_Lenth": 15.0
    },
    "mmlu_moral_scenarios_gpt4_style_in_context_examples": {
        "perplexity": 3.3377916955947877,
        "diversity_score": 0.0949,
        "complexity_score": 0.0342,
        "IDF_score": 0.484,
        "average_token_len": 269.48,
        "Average_Char_Lenth": 1076.8
    },
    "mmlu_moral_scenarios_openai_human_written_examples": {
        "perplexity": 4.601588773727417,
        "diversity_score": 0.0789,
        "complexity_score": 0.045,
        "IDF_score": 0.316,
        "average_token_len": 116.02,
        "Average_Char_Lenth": 496.42
    }
}