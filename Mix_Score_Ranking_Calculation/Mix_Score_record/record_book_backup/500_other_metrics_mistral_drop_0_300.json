{
    "drop_step_by_step": {
        "perplexity": 3.587841071685155,
        "IDF_score": 0.721,
        "log_propability": -215.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.03,
        "cos_similarity": 0.7099007161458334
    },
    "drop_claude": {
        "perplexity": 2.8544631604353587,
        "IDF_score": 0.558,
        "log_propability": -129.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.16,
        "cos_similarity": 0.7577457682291666
    },
    "drop_gpt4_style_in_context_examples": {
        "perplexity": 3.2140356600284576,
        "IDF_score": 0.635,
        "log_propability": -157.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.07,
        "cos_similarity": 0.7600048828125
    },
    "drop_gpt4": {
        "perplexity": 3.5106034608681997,
        "IDF_score": 0.6,
        "log_propability": -157.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.05,
        "cos_similarity": 0.7689103190104166
    },
    "drop_mini_gpt4": {
        "perplexity": 3.4838349465529124,
        "IDF_score": 0.57,
        "log_propability": -154.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.05,
        "cos_similarity": 0.7714111328125
    },
    "drop_groundtruth": {
        "perplexity": 319.1325619781017,
        "IDF_score": 3.82,
        "log_propability": -22.8,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 0.413,
        "cos_similarity": 0.3874306233723958
    },
    "drop_openai_human_written_examples": {
        "perplexity": 3.01088570634524,
        "IDF_score": 0.485,
        "log_propability": -110.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.14,
        "cos_similarity": 0.7830997721354167
    }
}