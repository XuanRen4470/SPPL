{
    "mmlu_moral_scenarios_step_by_step": {
        "perplexity": 3.416815185546875,
        "diversity_score": 0.0147,
        "complexity_score": 0.00807,
        "IDF_score": 0.524,
        "average_token_len": 226.15,
        "Average_Char_Lenth": 1091.45
    },
    "mmlu_moral_scenarios_gpt4": {
        "perplexity": 3.3194324135780335,
        "diversity_score": 0.0138,
        "complexity_score": 0.00791,
        "IDF_score": 0.404,
        "average_token_len": 150.1,
        "Average_Char_Lenth": 768.15
    },
    "mmlu_moral_scenarios_claude": {
        "perplexity": 2.5731930911540983,
        "diversity_score": 0.0108,
        "complexity_score": 0.00669,
        "IDF_score": 0.41,
        "average_token_len": 164.4,
        "Average_Char_Lenth": 823.75
    },
    "mmlu_moral_scenarios_mini_gpt4": {
        "perplexity": 2.97837690114975,
        "diversity_score": 0.0138,
        "complexity_score": 0.00683,
        "IDF_score": 0.37,
        "average_token_len": 139.25,
        "Average_Char_Lenth": 700.1
    },
    "mmlu_moral_scenarios_groundtruth": {
        "perplexity": 1787.3391571044922,
        "diversity_score": 0.138,
        "complexity_score": 0.00243,
        "IDF_score": 55.8,
        "average_token_len": 4.0,
        "Average_Char_Lenth": 15.0
    },
    "mmlu_moral_scenarios_gpt4_style_in_context_examples": {
        "perplexity": 3.1551194190979004,
        "diversity_score": 0.0121,
        "complexity_score": 0.00634,
        "IDF_score": 0.486,
        "average_token_len": 224.2,
        "Average_Char_Lenth": 1098.75
    },
    "mmlu_moral_scenarios_openai_human_written_examples": {
        "perplexity": 4.231598949432373,
        "diversity_score": 0.0197,
        "complexity_score": 0.0092,
        "IDF_score": 0.294,
        "average_token_len": 94.4,
        "Average_Char_Lenth": 477.8
    }
}