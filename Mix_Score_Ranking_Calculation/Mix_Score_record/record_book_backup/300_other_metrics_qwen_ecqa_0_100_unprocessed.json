{
    "ecqa_step_by_step": {
        "perplexity": 3.4401187229156496,
        "IDF_score": 0.747,
        "log_propability": -302.0,
        "skywork_reward_score": 12.59701171875,
        "CAR_score": 2.71
    },
    "ecqa_claude": {
        "perplexity": 2.9472100806236265,
        "IDF_score": 0.59,
        "log_propability": -181.0,
        "skywork_reward_score": 11.93869140625,
        "CAR_score": 2.84
    },
    "ecqa_gpt4_style_in_context_examples": {
        "perplexity": 3.45584525346756,
        "IDF_score": 0.716,
        "log_propability": -314.0,
        "skywork_reward_score": 18.1303515625,
        "CAR_score": 3.88
    },
    "ecqa_gpt4": {
        "perplexity": 3.6371813094615937,
        "IDF_score": 0.651,
        "log_propability": -232.0,
        "skywork_reward_score": 10.82961669921875,
        "CAR_score": 2.26
    },
    "ecqa_mini_gpt4": {
        "perplexity": 3.4787296223640443,
        "IDF_score": 0.58,
        "log_propability": -170.0,
        "skywork_reward_score": 7.60150390625,
        "CAR_score": 1.64
    },
    "ecqa_groundtruth": {
        "perplexity": 32.62840732097626,
        "IDF_score": 0.861,
        "log_propability": -169.0,
        "skywork_reward_score": 2.138232421875,
        "CAR_score": 0.196
    },
    "ecqa_openai_human_written_examples": {
        "perplexity": 3.4695384097099304,
        "IDF_score": 0.576,
        "log_propability": -186.0,
        "skywork_reward_score": 11.1918603515625,
        "CAR_score": 2.4
    },
    "ecqa_rewrite_groundtruth_in_own_words": {
        "perplexity": 5.483849463462829,
        "IDF_score": 0.548,
        "log_propability": -130.0,
        "skywork_reward_score": 4.32465087890625,
        "CAR_score": 0.727
    }
}