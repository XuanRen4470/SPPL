{
    "squad_step_by_step": {
        "perplexity": 3.1368773619333905,
        "IDF_score": 0.588,
        "log_propability": -148.0,
        "skywork_reward_score": 2.947981770833333,
        "CAR_score": 0.682
    },
    "squad_claude": {
        "perplexity": 2.6161703427632648,
        "IDF_score": 0.528,
        "log_propability": -114.0,
        "skywork_reward_score": 3.9740885416666667,
        "CAR_score": 1.03
    },
    "squad_gpt4_style_in_context_examples": {
        "perplexity": 3.149085776011149,
        "IDF_score": 0.602,
        "log_propability": -147.0,
        "skywork_reward_score": 2.8771158854166665,
        "CAR_score": 0.655
    },
    "squad_gpt4": {
        "perplexity": 4.017437601089478,
        "IDF_score": 0.541,
        "log_propability": -110.0,
        "skywork_reward_score": 2.265861002604167,
        "CAR_score": 0.459
    },
    "squad_mini_gpt4": {
        "perplexity": 3.680107514063517,
        "IDF_score": 0.505,
        "log_propability": -83.4,
        "skywork_reward_score": 2.6374186197916667,
        "CAR_score": 0.553
    },
    "squad_groundtruth": {
        "perplexity": 4.4807590564092,
        "IDF_score": 0.18,
        "log_propability": -7.01,
        "skywork_reward_score": 6.740625,
        "CAR_score": 1.41
    },
    "squad_openai_human_written_examples": {
        "perplexity": 2.6292767405509947,
        "IDF_score": 0.337,
        "log_propability": -48.1,
        "skywork_reward_score": 3.5692708333333334,
        "CAR_score": 0.945
    }
}