{
    "piqa_step_by_step": {
        "perplexity": 4.3711252053578695,
        "IDF_score": 0.658,
        "log_propability": -372.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.15,
        "cos_similarity": 0.8029134114583333
    },
    "piqa_claude": {
        "perplexity": 3.6245561440785727,
        "IDF_score": 0.57,
        "log_propability": -246.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.28,
        "cos_similarity": 0.8312174479166666
    },
    "piqa_gpt4_style_in_context_examples": {
        "perplexity": 5.7124061187108355,
        "IDF_score": 0.424,
        "log_propability": -188.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.01,
        "cos_similarity": 0.8245930989583333
    },
    "piqa_gpt4": {
        "perplexity": 6.4249344110488895,
        "IDF_score": 0.603,
        "log_propability": -240.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 0.965,
        "cos_similarity": 0.8392740885416666
    },
    "piqa_mini_gpt4": {
        "perplexity": 5.031507555643717,
        "IDF_score": 0.401,
        "log_propability": -187.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.09,
        "cos_similarity": 0.8551106770833333
    },
    "piqa_groundtruth": {
        "perplexity": 4459320.714339193,
        "IDF_score": 41800.0,
        "log_propability": -24.8,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 0.162,
        "cos_similarity": 0.13474527994791666
    },
    "piqa_openai_human_written_examples": {
        "perplexity": 6.397565507888794,
        "IDF_score": 0.317,
        "log_propability": -126.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 0.973,
        "cos_similarity": 0.80205078125
    }
}