{
    "plan_bench_generation_step_by_step": {
        "perplexity": 1.9854517340660096,
        "IDF_score": 0.702,
        "log_propability": -230.0,
        "skywork_reward_score": -7.711735026041667,
        "CAR_score": -2.58,
        "cos_similarity": 0.975
    },
    "plan_bench_generation_claude": {
        "perplexity": 1.964217984676361,
        "IDF_score": 0.591,
        "log_propability": -132.0,
        "skywork_reward_score": -7.711735026041667,
        "CAR_score": -2.58,
        "cos_similarity": 0.971533203125
    },
    "plan_bench_generation_gpt4_style_in_context_examples": {
        "perplexity": 2.391804814338684,
        "IDF_score": 0.737,
        "log_propability": -326.0,
        "skywork_reward_score": -7.711735026041667,
        "CAR_score": -2.16,
        "cos_similarity": 0.975390625
    },
    "plan_bench_generation_gpt4": {
        "perplexity": 2.581907558441162,
        "IDF_score": 0.697,
        "log_propability": -279.0,
        "skywork_reward_score": -7.711735026041667,
        "CAR_score": -2.03,
        "cos_similarity": 0.9671875
    },
    "plan_bench_generation_mini_gpt4": {
        "perplexity": 2.381023943424225,
        "IDF_score": 0.637,
        "log_propability": -264.0,
        "skywork_reward_score": -7.711735026041667,
        "CAR_score": -2.19,
        "cos_similarity": 0.972265625
    },
    "plan_bench_generation_groundtruth": {
        "perplexity": 68.1841594696045,
        "IDF_score": 1.22,
        "log_propability": -106.0,
        "skywork_reward_score": -7.711735026041667,
        "CAR_score": -0.67,
        "cos_similarity": 0.602685546875
    },
    "plan_bench_generation_openai_human_written_examples": {
        "perplexity": 2.482171583175659,
        "IDF_score": 0.67,
        "log_propability": -260.0,
        "skywork_reward_score": -7.711735026041667,
        "CAR_score": -2.09,
        "cos_similarity": 0.970703125
    },
    "plan_bench_generation_rewrite_groundtruth_in_own_words": {
        "perplexity": 2.958770751953125,
        "IDF_score": 0.712,
        "log_propability": -168.0,
        "skywork_reward_score": -7.711735026041667,
        "CAR_score": -1.84,
        "cos_similarity": 0.954052734375
    }
}