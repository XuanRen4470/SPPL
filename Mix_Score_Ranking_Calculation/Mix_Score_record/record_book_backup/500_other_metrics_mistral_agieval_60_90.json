{
    "agieval_step_by_step": {
        "perplexity": 4.084447511037191,
        "IDF_score": 0.539,
        "log_propability": -468.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 2.83,
        "cos_similarity": 0.8094645182291667
    },
    "agieval_claude": {
        "perplexity": 2.9737934947013853,
        "IDF_score": 0.479,
        "log_propability": -266.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 3.43,
        "cos_similarity": 0.8105550130208333
    },
    "agieval_gpt4_style_in_context_examples": {
        "perplexity": 3.9623074690500895,
        "IDF_score": 0.51,
        "log_propability": -492.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 2.87,
        "cos_similarity": 0.7977213541666667
    },
    "agieval_gpt4": {
        "perplexity": 4.355608908335368,
        "IDF_score": 0.49,
        "log_propability": -422.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 2.76,
        "cos_similarity": 0.8179280598958333
    },
    "agieval_mini_gpt4": {
        "perplexity": 4.013889463742574,
        "IDF_score": 0.468,
        "log_propability": -399.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 2.87,
        "cos_similarity": 0.8263427734375
    },
    "agieval_groundtruth": {
        "perplexity": 674468221.1318384,
        "IDF_score": 61700.0,
        "log_propability": -17.9,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 0.264,
        "cos_similarity": 0.0696608861287435
    },
    "agieval_openai_human_written_examples": {
        "perplexity": 4.339236378669739,
        "IDF_score": 0.458,
        "log_propability": -439.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 2.74,
        "cos_similarity": 0.8217122395833333
    }
}