{
    "winogrande_step_by_step": {
        "perplexity": 3.6299146127700808,
        "IDF_score": 0.723,
        "log_propability": -267.0,
        "skywork_reward_score": 11.402265625,
        "CAR_score": 2.36
    },
    "winogrande_claude": {
        "perplexity": 2.8923444414138793,
        "IDF_score": 0.54,
        "log_propability": -142.0,
        "skywork_reward_score": 11.51515625,
        "CAR_score": 2.78
    },
    "winogrande_gpt4_style_in_context_examples": {
        "perplexity": 3.019621057510376,
        "IDF_score": 0.496,
        "log_propability": -129.0,
        "skywork_reward_score": 13.3796875,
        "CAR_score": 3.16
    },
    "winogrande_gpt4": {
        "perplexity": 4.1982908010482785,
        "IDF_score": 0.572,
        "log_propability": -127.0,
        "skywork_reward_score": 11.357734375,
        "CAR_score": 2.2
    },
    "winogrande_mini_gpt4": {
        "perplexity": 3.2589616179466248,
        "IDF_score": 0.482,
        "log_propability": -115.0,
        "skywork_reward_score": 10.6903125,
        "CAR_score": 2.39
    },
    "winogrande_groundtruth": {
        "perplexity": 17066.530361328125,
        "IDF_score": 3.68,
        "log_propability": -1.63,
        "skywork_reward_score": 5.02259765625,
        "CAR_score": 0.173
    },
    "winogrande_openai_human_written_examples": {
        "perplexity": 3.438209962844849,
        "IDF_score": 0.397,
        "log_propability": -77.7,
        "skywork_reward_score": 10.4648828125,
        "CAR_score": 2.28
    }
}