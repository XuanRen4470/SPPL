{
    "piqa_step_by_step": {
        "perplexity": 4.228066539764404,
        "IDF_score": 0.668,
        "log_propability": -403.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.18,
        "cos_similarity": 0.783984375
    },
    "piqa_claude": {
        "perplexity": 3.937678961753845,
        "IDF_score": 0.551,
        "log_propability": -256.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.24,
        "cos_similarity": 0.8251708984375
    },
    "piqa_gpt4_style_in_context_examples": {
        "perplexity": 5.495614347457885,
        "IDF_score": 0.426,
        "log_propability": -207.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.05,
        "cos_similarity": 0.810126953125
    },
    "piqa_gpt4": {
        "perplexity": 6.0616559982299805,
        "IDF_score": 0.625,
        "log_propability": -303.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 0.984,
        "cos_similarity": 0.82275390625
    },
    "piqa_mini_gpt4": {
        "perplexity": 4.9552884197235105,
        "IDF_score": 0.443,
        "log_propability": -206.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.09,
        "cos_similarity": 0.825830078125
    },
    "piqa_groundtruth": {
        "perplexity": 3137930.5206640624,
        "IDF_score": 28700.0,
        "log_propability": -25.3,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 0.158,
        "cos_similarity": 0.13867919921875
    },
    "piqa_openai_human_written_examples": {
        "perplexity": 6.59060341835022,
        "IDF_score": 0.297,
        "log_propability": -123.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 0.968,
        "cos_similarity": 0.797412109375
    }
}