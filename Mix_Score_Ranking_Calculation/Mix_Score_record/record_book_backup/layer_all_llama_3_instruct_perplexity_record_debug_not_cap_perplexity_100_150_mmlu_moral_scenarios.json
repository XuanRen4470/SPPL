{
    "mmlu_moral_scenarios_step_by_step": {
        "perplexity": 3.532246389389038,
        "diversity_score": 0.0859,
        "complexity_score": 0.0278,
        "IDF_score": 0.43,
        "average_token_len": 233.28,
        "Average_Char_Lenth": 1134.88
    },
    "mmlu_moral_scenarios_gpt4": {
        "perplexity": 3.688979754447937,
        "diversity_score": 0.0604,
        "complexity_score": 0.0255,
        "IDF_score": 0.326,
        "average_token_len": 162.22,
        "Average_Char_Lenth": 836.44
    },
    "mmlu_moral_scenarios_claude": {
        "perplexity": 3.0361397790908815,
        "diversity_score": 0.0558,
        "complexity_score": 0.0268,
        "IDF_score": 0.326,
        "average_token_len": 156.3,
        "Average_Char_Lenth": 794.5
    },
    "mmlu_moral_scenarios_mini_gpt4": {
        "perplexity": 3.6262162017822264,
        "diversity_score": 0.0522,
        "complexity_score": 0.0247,
        "IDF_score": 0.314,
        "average_token_len": 137.38,
        "Average_Char_Lenth": 694.9
    },
    "mmlu_moral_scenarios_groundtruth": {
        "perplexity": 26.130567779541014,
        "diversity_score": 0.354,
        "complexity_score": 0.00157,
        "IDF_score": 0.115,
        "average_token_len": 4.0,
        "Average_Char_Lenth": 15.0
    },
    "mmlu_moral_scenarios_gpt4_style_in_context_examples": {
        "perplexity": 3.6497859716415406,
        "diversity_score": 0.0755,
        "complexity_score": 0.022,
        "IDF_score": 0.405,
        "average_token_len": 212.26,
        "Average_Char_Lenth": 1042.74
    },
    "mmlu_moral_scenarios_openai_human_written_examples": {
        "perplexity": 4.005499501228332,
        "diversity_score": 0.0509,
        "complexity_score": 0.0303,
        "IDF_score": 0.213,
        "average_token_len": 94.5,
        "Average_Char_Lenth": 479.92
    }
}