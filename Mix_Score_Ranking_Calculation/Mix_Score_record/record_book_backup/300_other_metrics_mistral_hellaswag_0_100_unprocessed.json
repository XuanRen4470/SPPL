{
    "hellaswag_step_by_step": {
        "perplexity": 4.918789775371551,
        "IDF_score": 0.657,
        "log_propability": -471.0,
        "skywork_reward_score": 5.730382690429687,
        "CAR_score": 1.0
    },
    "hellaswag_claude": {
        "perplexity": 4.052300958633423,
        "IDF_score": 0.606,
        "log_propability": -250.0,
        "skywork_reward_score": 7.611640625,
        "CAR_score": 1.48
    },
    "hellaswag_gpt4_style_in_context_examples": {
        "perplexity": 4.058044867515564,
        "IDF_score": 0.609,
        "log_propability": -393.0,
        "skywork_reward_score": 5.9812841796875,
        "CAR_score": 1.17
    },
    "hellaswag_gpt4": {
        "perplexity": 6.689287238121032,
        "IDF_score": 0.675,
        "log_propability": -359.0,
        "skywork_reward_score": 5.41076171875,
        "CAR_score": 0.837
    },
    "hellaswag_mini_gpt4": {
        "perplexity": 6.929821364879608,
        "IDF_score": 0.688,
        "log_propability": -280.0,
        "skywork_reward_score": 2.983203125,
        "CAR_score": 0.45
    },
    "hellaswag_groundtruth": {
        "perplexity": 21231716.233060304,
        "IDF_score": 2.79,
        "log_propability": -27.3,
        "skywork_reward_score": -17.301875,
        "CAR_score": -0.413
    },
    "hellaswag_openai_human_written_examples": {
        "perplexity": 6.529334392547607,
        "IDF_score": 0.628,
        "log_propability": -279.0,
        "skywork_reward_score": 6.0787890625,
        "CAR_score": 0.938
    }
}