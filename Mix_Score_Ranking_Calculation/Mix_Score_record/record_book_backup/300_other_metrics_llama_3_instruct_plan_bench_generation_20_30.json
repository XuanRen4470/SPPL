{
    "plan_bench_generation_step_by_step": {
        "perplexity": 2.126836967468262,
        "IDF_score": 0.624,
        "log_propability": -249.0,
        "skywork_reward_score": 0.273291015625,
        "CAR_score": 0.0863
    },
    "plan_bench_generation_claude": {
        "perplexity": 2.1101873397827147,
        "IDF_score": 0.593,
        "log_propability": -146.0,
        "skywork_reward_score": -2.8015625,
        "CAR_score": -0.873
    },
    "plan_bench_generation_gpt4_style_in_context_examples": {
        "perplexity": 2.419315683841705,
        "IDF_score": 0.67,
        "log_propability": -332.0,
        "skywork_reward_score": 1.62578125,
        "CAR_score": 0.451
    },
    "plan_bench_generation_gpt4": {
        "perplexity": 2.5420687913894655,
        "IDF_score": 0.638,
        "log_propability": -273.0,
        "skywork_reward_score": -0.646484375,
        "CAR_score": -0.172
    },
    "plan_bench_generation_mini_gpt4": {
        "perplexity": 2.730531895160675,
        "IDF_score": 0.675,
        "log_propability": -303.0,
        "skywork_reward_score": -5.761328125,
        "CAR_score": -1.48
    },
    "plan_bench_generation_groundtruth": {
        "perplexity": 12.838144397735595,
        "IDF_score": 0.602,
        "log_propability": -65.6,
        "skywork_reward_score": -12.64375,
        "CAR_score": -1.66
    },
    "plan_bench_generation_openai_human_written_examples": {
        "perplexity": 2.6177409648895265,
        "IDF_score": 0.659,
        "log_propability": -278.0,
        "skywork_reward_score": -1.94453125,
        "CAR_score": -0.505
    },
    "plan_bench_generation_rewrite_groundtruth_in_own_words": {
        "perplexity": 2.8578946590423584,
        "IDF_score": 0.7,
        "log_propability": -164.0,
        "skywork_reward_score": -8.778125,
        "CAR_score": -2.14
    }
}