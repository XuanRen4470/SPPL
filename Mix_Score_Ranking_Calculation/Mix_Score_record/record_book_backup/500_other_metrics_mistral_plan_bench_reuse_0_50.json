{
    "plan_bench_reuse_step_by_step": {
        "perplexity": 2.6809114480018614,
        "IDF_score": 0.715,
        "log_propability": -357.0,
        "skywork_reward_score": -16.733743489583333,
        "CAR_score": -4.32,
        "cos_similarity": 0.842783203125
    },
    "plan_bench_reuse_claude": {
        "perplexity": 3.023898537158966,
        "IDF_score": 0.611,
        "log_propability": -243.0,
        "skywork_reward_score": -16.733743489583333,
        "CAR_score": -3.98,
        "cos_similarity": 0.85333984375
    },
    "plan_bench_reuse_gpt4_style_in_context_examples": {
        "perplexity": 2.4339847111701967,
        "IDF_score": 0.739,
        "log_propability": -361.0,
        "skywork_reward_score": -16.733743489583333,
        "CAR_score": -4.63,
        "cos_similarity": 0.8359375
    },
    "plan_bench_reuse_gpt4": {
        "perplexity": 2.901966300010681,
        "IDF_score": 0.694,
        "log_propability": -354.0,
        "skywork_reward_score": -16.733743489583333,
        "CAR_score": -4.08,
        "cos_similarity": 0.856748046875
    },
    "plan_bench_reuse_mini_gpt4": {
        "perplexity": 3.5990734481811524,
        "IDF_score": 0.645,
        "log_propability": -449.0,
        "skywork_reward_score": -16.733743489583333,
        "CAR_score": -3.54,
        "cos_similarity": 0.87091796875
    },
    "plan_bench_reuse_groundtruth": {
        "perplexity": 1083.417358341217,
        "IDF_score": 1.35,
        "log_propability": -99.4,
        "skywork_reward_score": -16.733743489583333,
        "CAR_score": -1.06,
        "cos_similarity": 0.4003466796875
    },
    "plan_bench_reuse_openai_human_written_examples": {
        "perplexity": 4.264129331111908,
        "IDF_score": 0.596,
        "log_propability": -298.0,
        "skywork_reward_score": -16.733743489583333,
        "CAR_score": -3.29,
        "cos_similarity": 0.865439453125
    },
    "plan_bench_reuse_rewrite_groundtruth_in_own_words": {
        "perplexity": 4.501762619018555,
        "IDF_score": 0.547,
        "log_propability": -273.0,
        "skywork_reward_score": -16.733743489583333,
        "CAR_score": -3.18,
        "cos_similarity": 0.853076171875
    }
}