{
    "ecqa_step_by_step": {
        "perplexity": 4.455939881006876,
        "IDF_score": 0.742,
        "log_propability": -409.0,
        "skywork_reward_score": 11.196549479166666,
        "CAR_score": 2.07
    },
    "ecqa_claude": {
        "perplexity": 4.002583130200704,
        "IDF_score": 0.656,
        "log_propability": -266.0,
        "skywork_reward_score": 11.117317708333333,
        "CAR_score": 2.18
    },
    "ecqa_gpt4_style_in_context_examples": {
        "perplexity": 4.469182014465332,
        "IDF_score": 0.725,
        "log_propability": -430.0,
        "skywork_reward_score": 17.959375,
        "CAR_score": 3.29
    },
    "ecqa_gpt4": {
        "perplexity": 5.635787971814474,
        "IDF_score": 0.723,
        "log_propability": -341.0,
        "skywork_reward_score": 9.071736653645834,
        "CAR_score": 1.51
    },
    "ecqa_mini_gpt4": {
        "perplexity": 6.016652536392212,
        "IDF_score": 0.678,
        "log_propability": -280.0,
        "skywork_reward_score": 6.448697916666666,
        "CAR_score": 1.03
    },
    "ecqa_groundtruth": {
        "perplexity": 77.61622320810953,
        "IDF_score": 1.05,
        "log_propability": -246.0,
        "skywork_reward_score": 1.619921875,
        "CAR_score": 0.12
    },
    "ecqa_openai_human_written_examples": {
        "perplexity": 6.078462743759156,
        "IDF_score": 0.681,
        "log_propability": -285.0,
        "skywork_reward_score": 10.361458333333333,
        "CAR_score": 1.67
    },
    "ecqa_rewrite_groundtruth_in_own_words": {
        "perplexity": 10.123737557729084,
        "IDF_score": 0.695,
        "log_propability": -196.0,
        "skywork_reward_score": 2.2756591796875,
        "CAR_score": 0.291
    }
}