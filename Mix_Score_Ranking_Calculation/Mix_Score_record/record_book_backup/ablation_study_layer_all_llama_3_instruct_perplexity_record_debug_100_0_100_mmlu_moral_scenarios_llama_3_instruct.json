{
    "mmlu_moral_scenarios_step_by_step": {
        "perplexity": 3.6554145193099976,
        "complexity_score": 0.0275,
        "IDF_score": 0.423,
        "average_token_len": 228.34,
        "Average_Char_Lenth": 1117.41,
        "average_loss_score": 1.28,
        "skywork_reward_score": 9.1330322265625,
        "CAR_score": 1.89
    },
    "mmlu_moral_scenarios_gpt4": {
        "perplexity": 3.573605058193207,
        "complexity_score": 0.0275,
        "IDF_score": 0.306,
        "average_token_len": 153.31,
        "Average_Char_Lenth": 790.6,
        "average_loss_score": 1.25,
        "skywork_reward_score": 13.5050537109375,
        "CAR_score": 2.83
    },
    "mmlu_moral_scenarios_claude": {
        "perplexity": 3.0716342663764955,
        "complexity_score": 0.0274,
        "IDF_score": 0.333,
        "average_token_len": 159.39,
        "Average_Char_Lenth": 815.29,
        "average_loss_score": 1.11,
        "skywork_reward_score": 22.9648193359375,
        "CAR_score": 5.32
    },
    "mmlu_moral_scenarios_mini_gpt4": {
        "perplexity": 3.5992379117012026,
        "complexity_score": 0.0245,
        "IDF_score": 0.324,
        "average_token_len": 140.58,
        "Average_Char_Lenth": 708.96,
        "average_loss_score": 1.26,
        "skywork_reward_score": 28.4735693359375,
        "CAR_score": 5.95
    },
    "mmlu_moral_scenarios_groundtruth": {
        "perplexity": 25.516091480255128,
        "complexity_score": 0.00145,
        "IDF_score": 0.113,
        "average_token_len": 4.0,
        "Average_Char_Lenth": 15.0,
        "average_loss_score": 3.22,
        "skywork_reward_score": 21.272451171875,
        "CAR_score": 1.99
    },
    "mmlu_moral_scenarios_gpt4_style_in_context_examples": {
        "perplexity": 3.6904109621047976,
        "complexity_score": 0.0219,
        "IDF_score": 0.419,
        "average_token_len": 217.75,
        "Average_Char_Lenth": 1067.22,
        "average_loss_score": 1.29,
        "skywork_reward_score": 30.384185791015625,
        "CAR_score": 6.22
    },
    "mmlu_moral_scenarios_openai_human_written_examples": {
        "perplexity": 3.9261553144454955,
        "complexity_score": 0.0305,
        "IDF_score": 0.221,
        "average_token_len": 96.55,
        "Average_Char_Lenth": 488.24,
        "average_loss_score": 1.34,
        "skywork_reward_score": 32.82595336914063,
        "CAR_score": 6.55
    }
}