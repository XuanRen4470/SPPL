{
    "squad_step_by_step": {
        "perplexity": 3.8939122438430784,
        "IDF_score": 0.745,
        "log_propability": -209.0,
        "skywork_reward_score": 3.678125,
        "CAR_score": 0.749
    },
    "squad_claude": {
        "perplexity": 3.041027855873108,
        "IDF_score": 0.679,
        "log_propability": -170.0,
        "skywork_reward_score": 3.92412109375,
        "CAR_score": 0.915
    },
    "squad_gpt4_style_in_context_examples": {
        "perplexity": 3.76257004737854,
        "IDF_score": 0.816,
        "log_propability": -209.0,
        "skywork_reward_score": 2.78203125,
        "CAR_score": 0.567
    },
    "squad_gpt4": {
        "perplexity": 4.730836033821106,
        "IDF_score": 0.736,
        "log_propability": -162.0,
        "skywork_reward_score": 3.06611328125,
        "CAR_score": 0.552
    },
    "squad_mini_gpt4": {
        "perplexity": 5.289783072471619,
        "IDF_score": 0.723,
        "log_propability": -142.0,
        "skywork_reward_score": 2.74248046875,
        "CAR_score": 0.471
    },
    "squad_groundtruth": {
        "perplexity": 173.1210412979126,
        "IDF_score": 0.407,
        "log_propability": -14.2,
        "skywork_reward_score": 9.47421875,
        "CAR_score": 0.999
    },
    "squad_openai_human_written_examples": {
        "perplexity": 2.7170525193214417,
        "IDF_score": 0.411,
        "log_propability": -64.3,
        "skywork_reward_score": 6.190625,
        "CAR_score": 1.59
    }
}