{
    "mmlu_moral_scenarios_step_by_step": {
        "perplexity": 3.321127724647522,
        "diversity_score": 0.0144,
        "complexity_score": 0.00789,
        "IDF_score": 0.519,
        "average_token_len": 226.6,
        "Average_Char_Lenth": 1084.5666666666666
    },
    "mmlu_moral_scenarios_gpt4": {
        "perplexity": 3.2251592953999837,
        "diversity_score": 0.013,
        "complexity_score": 0.00785,
        "IDF_score": 0.39,
        "average_token_len": 149.06666666666666,
        "Average_Char_Lenth": 756.2333333333333
    },
    "mmlu_moral_scenarios_claude": {
        "perplexity": 2.5472625215848286,
        "diversity_score": 0.0103,
        "complexity_score": 0.00678,
        "IDF_score": 0.411,
        "average_token_len": 163.03333333333333,
        "Average_Char_Lenth": 820.6
    },
    "mmlu_moral_scenarios_mini_gpt4": {
        "perplexity": 2.9664133469263714,
        "diversity_score": 0.0132,
        "complexity_score": 0.00681,
        "IDF_score": 0.363,
        "average_token_len": 136.96666666666667,
        "Average_Char_Lenth": 687.0333333333333
    },
    "mmlu_moral_scenarios_groundtruth": {
        "perplexity": 2038.3425018310547,
        "diversity_score": 0.138,
        "complexity_score": 0.00253,
        "IDF_score": 63.3,
        "average_token_len": 4.0,
        "Average_Char_Lenth": 15.0
    },
    "mmlu_moral_scenarios_gpt4_style_in_context_examples": {
        "perplexity": 3.11946116288503,
        "diversity_score": 0.0118,
        "complexity_score": 0.00628,
        "IDF_score": 0.49,
        "average_token_len": 221.63333333333333,
        "Average_Char_Lenth": 1077.4333333333334
    },
    "mmlu_moral_scenarios_openai_human_written_examples": {
        "perplexity": 4.208011809984843,
        "diversity_score": 0.0203,
        "complexity_score": 0.0095,
        "IDF_score": 0.283,
        "average_token_len": 94.03333333333333,
        "Average_Char_Lenth": 475.96666666666664
    }
}