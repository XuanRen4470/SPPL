{
    "boolq_step_by_step": {
        "perplexity": 4.263294520378113,
        "IDF_score": 0.595,
        "log_propability": -251.0,
        "skywork_reward_score": 9.431002604166666,
        "CAR_score": 1.8,
        "cos_similarity": 0.792109375
    },
    "boolq_claude": {
        "perplexity": 3.1742781198024748,
        "IDF_score": 0.529,
        "log_propability": -218.0,
        "skywork_reward_score": 9.431002604166666,
        "CAR_score": 2.15,
        "cos_similarity": 0.8357421875
    },
    "boolq_gpt4_style_in_context_examples": {
        "perplexity": 3.9703270065784455,
        "IDF_score": 0.393,
        "log_propability": -137.0,
        "skywork_reward_score": 9.431002604166666,
        "CAR_score": 1.92,
        "cos_similarity": 0.82849609375
    },
    "boolq_gpt4": {
        "perplexity": 4.476978746652603,
        "IDF_score": 0.567,
        "log_propability": -189.0,
        "skywork_reward_score": 9.431002604166666,
        "CAR_score": 1.78,
        "cos_similarity": 0.8599462890625
    },
    "boolq_mini_gpt4": {
        "perplexity": 4.766248831748962,
        "IDF_score": 0.502,
        "log_propability": -143.0,
        "skywork_reward_score": 9.431002604166666,
        "CAR_score": 1.72,
        "cos_similarity": 0.85150390625
    },
    "boolq_groundtruth": {
        "perplexity": 97389.74674804688,
        "IDF_score": 86.8,
        "log_propability": -15.5,
        "skywork_reward_score": 9.431002604166666,
        "CAR_score": 0.274,
        "cos_similarity": 0.20695220947265625
    },
    "boolq_openai_human_written_examples": {
        "perplexity": 3.379033668041229,
        "IDF_score": 0.315,
        "log_propability": -108.0,
        "skywork_reward_score": 9.431002604166666,
        "CAR_score": 2.12,
        "cos_similarity": 0.8003125
    }
}