{
    "mmlu_moral_scenarios_step_by_step": {
        "perplexity": 3.919868450164795,
        "diversity_score": 0.0915,
        "complexity_score": 0.0437,
        "IDF_score": 0.545,
        "average_token_len": 267.53,
        "Average_Char_Lenth": 1117.41
    },
    "mmlu_moral_scenarios_gpt4": {
        "perplexity": 3.9974984908103943,
        "diversity_score": 0.0702,
        "complexity_score": 0.0416,
        "IDF_score": 0.408,
        "average_token_len": 181.77,
        "Average_Char_Lenth": 790.6
    },
    "mmlu_moral_scenarios_claude": {
        "perplexity": 2.9946704959869384,
        "diversity_score": 0.0739,
        "complexity_score": 0.0439,
        "IDF_score": 0.406,
        "average_token_len": 190.56,
        "Average_Char_Lenth": 815.29
    },
    "mmlu_moral_scenarios_mini_gpt4": {
        "perplexity": 3.6598226165771486,
        "diversity_score": 0.0684,
        "complexity_score": 0.0404,
        "IDF_score": 0.372,
        "average_token_len": 165.39,
        "Average_Char_Lenth": 708.96
    },
    "mmlu_moral_scenarios_groundtruth": {
        "perplexity": 47945.70593261719,
        "diversity_score": 0.36,
        "complexity_score": 0.00236,
        "IDF_score": 79.4,
        "average_token_len": 5.0,
        "Average_Char_Lenth": 15.0
    },
    "mmlu_moral_scenarios_gpt4_style_in_context_examples": {
        "perplexity": 3.2851565861701966,
        "diversity_score": 0.0949,
        "complexity_score": 0.0344,
        "IDF_score": 0.482,
        "average_token_len": 266.67,
        "Average_Char_Lenth": 1067.22
    },
    "mmlu_moral_scenarios_openai_human_written_examples": {
        "perplexity": 4.669678924083709,
        "diversity_score": 0.0789,
        "complexity_score": 0.0455,
        "IDF_score": 0.324,
        "average_token_len": 114.74,
        "Average_Char_Lenth": 488.24
    }
}