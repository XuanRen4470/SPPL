{
    "piqa_step_by_step": {
        "perplexity": 4.351866593360901,
        "IDF_score": 0.675,
        "log_propability": -395.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.15,
        "cos_similarity": 0.804755859375
    },
    "piqa_claude": {
        "perplexity": 3.666686272621155,
        "IDF_score": 0.579,
        "log_propability": -254.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.28,
        "cos_similarity": 0.83697265625
    },
    "piqa_gpt4_style_in_context_examples": {
        "perplexity": 5.8626259994506835,
        "IDF_score": 0.429,
        "log_propability": -198.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.0,
        "cos_similarity": 0.828701171875
    },
    "piqa_gpt4": {
        "perplexity": 6.4925844192504885,
        "IDF_score": 0.603,
        "log_propability": -247.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 0.96,
        "cos_similarity": 0.836357421875
    },
    "piqa_mini_gpt4": {
        "perplexity": 5.075491147041321,
        "IDF_score": 0.422,
        "log_propability": -197.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 1.08,
        "cos_similarity": 0.8525390625
    },
    "piqa_groundtruth": {
        "perplexity": 9599351.998330079,
        "IDF_score": 88000.0,
        "log_propability": -24.9,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 0.161,
        "cos_similarity": 0.1333935546875
    },
    "piqa_openai_human_written_examples": {
        "perplexity": 6.342406449317932,
        "IDF_score": 0.307,
        "log_propability": -124.0,
        "skywork_reward_score": 6.174027404785156,
        "CAR_score": 0.978,
        "cos_similarity": 0.804697265625
    }
}