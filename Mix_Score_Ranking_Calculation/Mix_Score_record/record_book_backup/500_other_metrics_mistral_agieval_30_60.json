{
    "agieval_step_by_step": {
        "perplexity": 4.226180855433146,
        "IDF_score": 0.554,
        "log_propability": -487.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 2.8,
        "cos_similarity": 0.809228515625
    },
    "agieval_claude": {
        "perplexity": 3.1316592057545978,
        "IDF_score": 0.494,
        "log_propability": -272.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 3.3,
        "cos_similarity": 0.8218424479166667
    },
    "agieval_gpt4_style_in_context_examples": {
        "perplexity": 4.204355581601461,
        "IDF_score": 0.549,
        "log_propability": -532.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 2.79,
        "cos_similarity": 0.785546875
    },
    "agieval_gpt4": {
        "perplexity": 4.240373384952545,
        "IDF_score": 0.517,
        "log_propability": -428.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 2.81,
        "cos_similarity": 0.8169759114583334
    },
    "agieval_mini_gpt4": {
        "perplexity": 4.095811200141907,
        "IDF_score": 0.49,
        "log_propability": -450.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 2.82,
        "cos_similarity": 0.8173014322916666
    },
    "agieval_groundtruth": {
        "perplexity": 198058954.62950236,
        "IDF_score": 18600.0,
        "log_propability": -15.7,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 0.301,
        "cos_similarity": 0.04297930399576823
    },
    "agieval_openai_human_written_examples": {
        "perplexity": 4.14352810382843,
        "IDF_score": 0.467,
        "log_propability": -436.0,
        "skywork_reward_score": 14.463245442708333,
        "CAR_score": 2.81,
        "cos_similarity": 0.8200846354166667
    }
}