{
    "squad_step_by_step": {
        "perplexity": 3.9209452152252195,
        "IDF_score": 0.721,
        "log_propability": -219.0,
        "skywork_reward_score": 2.5309159342447916,
        "CAR_score": 0.513
    },
    "squad_claude": {
        "perplexity": 2.9575178098678587,
        "IDF_score": 0.566,
        "log_propability": -160.0,
        "skywork_reward_score": 2.8419281005859376,
        "CAR_score": 0.683
    },
    "squad_gpt4_style_in_context_examples": {
        "perplexity": 3.6615876825650533,
        "IDF_score": 0.758,
        "log_propability": -219.0,
        "skywork_reward_score": 2.4217146809895835,
        "CAR_score": 0.502
    },
    "squad_gpt4": {
        "perplexity": 5.668071528673172,
        "IDF_score": 0.693,
        "log_propability": -171.0,
        "skywork_reward_score": 2.176976725260417,
        "CAR_score": 0.374
    },
    "squad_mini_gpt4": {
        "perplexity": 4.531965852181116,
        "IDF_score": 0.627,
        "log_propability": -129.0,
        "skywork_reward_score": 2.476246337890625,
        "CAR_score": 0.465
    },
    "squad_groundtruth": {
        "perplexity": 57.379395573536556,
        "IDF_score": 0.344,
        "log_propability": -13.1,
        "skywork_reward_score": 6.125341796875,
        "CAR_score": 0.867
    },
    "squad_openai_human_written_examples": {
        "perplexity": 3.2380659484863283,
        "IDF_score": 0.443,
        "log_propability": -73.9,
        "skywork_reward_score": 3.81082275390625,
        "CAR_score": 0.899
    }
}