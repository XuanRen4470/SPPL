{
    "squad_step_by_step": {
        "perplexity": 3.8505740722020465,
        "IDF_score": 0.73,
        "log_propability": -204.0,
        "skywork_reward_score": 2.947981770833333,
        "CAR_score": 0.603
    },
    "squad_claude": {
        "perplexity": 3.1670510808626813,
        "IDF_score": 0.602,
        "log_propability": -155.0,
        "skywork_reward_score": 3.9740885416666667,
        "CAR_score": 0.914
    },
    "squad_gpt4_style_in_context_examples": {
        "perplexity": 3.817160193125407,
        "IDF_score": 0.781,
        "log_propability": -199.0,
        "skywork_reward_score": 2.8771158854166665,
        "CAR_score": 0.583
    },
    "squad_gpt4": {
        "perplexity": 5.459509400526683,
        "IDF_score": 0.666,
        "log_propability": -150.0,
        "skywork_reward_score": 2.265861002604167,
        "CAR_score": 0.394
    },
    "squad_mini_gpt4": {
        "perplexity": 4.996442874272664,
        "IDF_score": 0.635,
        "log_propability": -117.0,
        "skywork_reward_score": 2.6374186197916667,
        "CAR_score": 0.473
    },
    "squad_groundtruth": {
        "perplexity": 39.569856746991476,
        "IDF_score": 0.402,
        "log_propability": -15.1,
        "skywork_reward_score": 6.740625,
        "CAR_score": 0.861
    },
    "squad_openai_human_written_examples": {
        "perplexity": 3.577102200190226,
        "IDF_score": 0.455,
        "log_propability": -71.9,
        "skywork_reward_score": 3.5692708333333334,
        "CAR_score": 0.789
    }
}