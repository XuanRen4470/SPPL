{
    "hellaswag_step_by_step": {
        "perplexity": 4.833749922116597,
        "IDF_score": 0.666,
        "log_propability": -442.0,
        "skywork_reward_score": 6.146875,
        "CAR_score": 1.09
    },
    "hellaswag_claude": {
        "perplexity": 3.9689822594324746,
        "IDF_score": 0.602,
        "log_propability": -247.0,
        "skywork_reward_score": 7.591145833333333,
        "CAR_score": 1.49
    },
    "hellaswag_gpt4_style_in_context_examples": {
        "perplexity": 3.79470948378245,
        "IDF_score": 0.594,
        "log_propability": -372.0,
        "skywork_reward_score": 6.599739583333333,
        "CAR_score": 1.33
    },
    "hellaswag_gpt4": {
        "perplexity": 6.731436491012573,
        "IDF_score": 0.686,
        "log_propability": -326.0,
        "skywork_reward_score": 5.527604166666666,
        "CAR_score": 0.841
    },
    "hellaswag_mini_gpt4": {
        "perplexity": 7.027185352643331,
        "IDF_score": 0.686,
        "log_propability": -263.0,
        "skywork_reward_score": 3.257942708333333,
        "CAR_score": 0.489
    },
    "hellaswag_groundtruth": {
        "perplexity": 49622090.60789388,
        "IDF_score": 2.73,
        "log_propability": -27.3,
        "skywork_reward_score": -16.889583333333334,
        "CAR_score": -0.403
    },
    "hellaswag_openai_human_written_examples": {
        "perplexity": 5.951167249679566,
        "IDF_score": 0.62,
        "log_propability": -262.0,
        "skywork_reward_score": 6.244401041666666,
        "CAR_score": 1.0
    }
}