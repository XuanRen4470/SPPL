{
    "plan_bench_generation_step_by_step": {
        "perplexity": 2.1870534563064576,
        "IDF_score": 0.643,
        "log_propability": -283.0,
        "skywork_reward_score": 0.2068359375,
        "CAR_score": 0.0634
    },
    "plan_bench_generation_claude": {
        "perplexity": 2.1294069409370424,
        "IDF_score": 0.596,
        "log_propability": -157.0,
        "skywork_reward_score": -3.15870849609375,
        "CAR_score": -0.975
    },
    "plan_bench_generation_gpt4_style_in_context_examples": {
        "perplexity": 2.367857565879822,
        "IDF_score": 0.672,
        "log_propability": -335.0,
        "skywork_reward_score": 1.6869921875,
        "CAR_score": 0.481
    },
    "plan_bench_generation_gpt4": {
        "perplexity": 2.266416049003601,
        "IDF_score": 0.639,
        "log_propability": -266.0,
        "skywork_reward_score": -0.085421142578125,
        "CAR_score": -0.0253
    },
    "plan_bench_generation_mini_gpt4": {
        "perplexity": 2.752193510532379,
        "IDF_score": 0.692,
        "log_propability": -320.0,
        "skywork_reward_score": -4.25755859375,
        "CAR_score": -1.08
    },
    "plan_bench_generation_groundtruth": {
        "perplexity": 17.74965184688568,
        "IDF_score": 0.615,
        "log_propability": -68.1,
        "skywork_reward_score": -12.238125,
        "CAR_score": -1.64
    },
    "plan_bench_generation_openai_human_written_examples": {
        "perplexity": 2.7245939636230467,
        "IDF_score": 0.673,
        "log_propability": -286.0,
        "skywork_reward_score": -1.71994140625,
        "CAR_score": -0.436
    },
    "plan_bench_generation_rewrite_groundtruth_in_own_words": {
        "perplexity": 2.892708430290222,
        "IDF_score": 0.691,
        "log_propability": -182.0,
        "skywork_reward_score": -8.009453125,
        "CAR_score": -1.99
    }
}