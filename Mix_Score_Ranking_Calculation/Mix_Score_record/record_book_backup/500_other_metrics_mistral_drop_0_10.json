{
    "drop_step_by_step": {
        "perplexity": 3.6814687252044678,
        "IDF_score": 0.798,
        "log_propability": -263.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 0.985,
        "cos_similarity": 0.62939453125
    },
    "drop_claude": {
        "perplexity": 2.976485347747803,
        "IDF_score": 0.549,
        "log_propability": -125.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.13,
        "cos_similarity": 0.73076171875
    },
    "drop_gpt4_style_in_context_examples": {
        "perplexity": 3.5593711137771606,
        "IDF_score": 0.656,
        "log_propability": -183.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 0.986,
        "cos_similarity": 0.7111328125
    },
    "drop_gpt4": {
        "perplexity": 3.9081215858459473,
        "IDF_score": 0.612,
        "log_propability": -208.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 0.947,
        "cos_similarity": 0.720361328125
    },
    "drop_mini_gpt4": {
        "perplexity": 3.523365330696106,
        "IDF_score": 0.414,
        "log_propability": -105.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 0.996,
        "cos_similarity": 0.772607421875
    },
    "drop_groundtruth": {
        "perplexity": 287.19992995262146,
        "IDF_score": 2.14,
        "log_propability": -18.1,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 0.441,
        "cos_similarity": 0.39482421875
    },
    "drop_openai_human_written_examples": {
        "perplexity": 3.337371063232422,
        "IDF_score": 0.444,
        "log_propability": -119.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.06,
        "cos_similarity": 0.7384765625
    }
}