{
    "hellaswag_step_by_step": {
        "perplexity": 4.6109382065137225,
        "IDF_score": 0.609,
        "log_propability": -386.0,
        "skywork_reward_score": 5.565889282226562,
        "CAR_score": 1.01
    },
    "hellaswag_claude": {
        "perplexity": 3.865671033859253,
        "IDF_score": 0.587,
        "log_propability": -213.0,
        "skywork_reward_score": 7.4029541015625,
        "CAR_score": 1.48
    },
    "hellaswag_gpt4_style_in_context_examples": {
        "perplexity": 3.469064257144928,
        "IDF_score": 0.525,
        "log_propability": -313.0,
        "skywork_reward_score": 5.8176806640625,
        "CAR_score": 1.24
    },
    "hellaswag_gpt4": {
        "perplexity": 5.310634228388468,
        "IDF_score": 0.602,
        "log_propability": -297.0,
        "skywork_reward_score": 5.2866845703125,
        "CAR_score": 0.897
    },
    "hellaswag_mini_gpt4": {
        "perplexity": 5.458317912419637,
        "IDF_score": 0.638,
        "log_propability": -241.0,
        "skywork_reward_score": 3.375640869140625,
        "CAR_score": 0.561
    },
    "hellaswag_groundtruth": {
        "perplexity": 66.57782081604005,
        "IDF_score": Infinity,
        "log_propability": -8.03,
        "skywork_reward_score": -17.539583333333333,
        "CAR_score": -1.34
    },
    "hellaswag_openai_human_written_examples": {
        "perplexity": 5.1100453249613444,
        "IDF_score": 0.577,
        "log_propability": -225.0,
        "skywork_reward_score": 5.702202351888021,
        "CAR_score": 0.983
    }
}