{
    "squad_step_by_step": {
        "perplexity": 3.651058475971222,
        "IDF_score": 0.683,
        "log_propability": -200.0,
        "skywork_reward_score": 1.905535888671875,
        "CAR_score": 0.4
    },
    "squad_claude": {
        "perplexity": 2.998619406223297,
        "IDF_score": 0.549,
        "log_propability": -160.0,
        "skywork_reward_score": 2.456649169921875,
        "CAR_score": 0.586
    },
    "squad_gpt4_style_in_context_examples": {
        "perplexity": 3.4956520891189573,
        "IDF_score": 0.741,
        "log_propability": -211.0,
        "skywork_reward_score": 2.14878662109375,
        "CAR_score": 0.455
    },
    "squad_gpt4": {
        "perplexity": 6.021751067638397,
        "IDF_score": 0.682,
        "log_propability": -165.0,
        "skywork_reward_score": 1.569736328125,
        "CAR_score": 0.262
    },
    "squad_mini_gpt4": {
        "perplexity": 4.219567563533783,
        "IDF_score": 0.605,
        "log_propability": -120.0,
        "skywork_reward_score": 2.492025146484375,
        "CAR_score": 0.483
    },
    "squad_groundtruth": {
        "perplexity": 38.01061749339104,
        "IDF_score": 0.356,
        "log_propability": -13.2,
        "skywork_reward_score": 6.017802734375,
        "CAR_score": 0.844
    },
    "squad_openai_human_written_examples": {
        "perplexity": 3.1047962057590484,
        "IDF_score": 0.435,
        "log_propability": -71.7,
        "skywork_reward_score": 3.42791015625,
        "CAR_score": 0.824
    }
}