{
    "drop_step_by_step": {
        "perplexity": 3.322302453517914,
        "IDF_score": 0.721,
        "log_propability": -182.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.04,
        "cos_similarity": 0.78033203125
    },
    "drop_claude": {
        "perplexity": 3.0545271897315978,
        "IDF_score": 0.599,
        "log_propability": -116.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.09,
        "cos_similarity": 0.811181640625
    },
    "drop_gpt4_style_in_context_examples": {
        "perplexity": 3.1247422552108763,
        "IDF_score": 0.638,
        "log_propability": -136.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.09,
        "cos_similarity": 0.81423828125
    },
    "drop_gpt4": {
        "perplexity": 3.119625914096832,
        "IDF_score": 0.63,
        "log_propability": -117.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.11,
        "cos_similarity": 0.83091796875
    },
    "drop_mini_gpt4": {
        "perplexity": 2.6077295899391175,
        "IDF_score": 0.59,
        "log_propability": -118.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.22,
        "cos_similarity": 0.83544921875
    },
    "drop_groundtruth": {
        "perplexity": 343.96407514333725,
        "IDF_score": 6.07,
        "log_propability": -24.5,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 0.457,
        "cos_similarity": 0.4137255859375
    },
    "drop_openai_human_written_examples": {
        "perplexity": 2.619425232410431,
        "IDF_score": 0.484,
        "log_propability": -84.7,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.25,
        "cos_similarity": 0.839658203125
    }
}