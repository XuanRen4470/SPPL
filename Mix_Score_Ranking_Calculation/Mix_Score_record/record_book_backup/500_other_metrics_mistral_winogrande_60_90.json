{
    "winogrande_step_by_step": {
        "perplexity": 5.402698270479838,
        "IDF_score": 0.591,
        "log_propability": -356.0,
        "skywork_reward_score": 11.346097513834636,
        "CAR_score": 1.91,
        "cos_similarity": 0.6827962239583333
    },
    "winogrande_claude": {
        "perplexity": 4.097180581092834,
        "IDF_score": 0.507,
        "log_propability": -232.0,
        "skywork_reward_score": 11.346097513834636,
        "CAR_score": 2.2,
        "cos_similarity": 0.6891560872395833
    },
    "winogrande_gpt4_style_in_context_examples": {
        "perplexity": 4.931006447474162,
        "IDF_score": 0.431,
        "log_propability": -215.0,
        "skywork_reward_score": 11.346097513834636,
        "CAR_score": 2.01,
        "cos_similarity": 0.7141276041666667
    },
    "winogrande_gpt4": {
        "perplexity": 7.029574990272522,
        "IDF_score": 0.375,
        "log_propability": -173.0,
        "skywork_reward_score": 11.346097513834636,
        "CAR_score": 1.76,
        "cos_similarity": 0.73720703125
    },
    "winogrande_mini_gpt4": {
        "perplexity": 6.541642340024312,
        "IDF_score": 0.393,
        "log_propability": -195.0,
        "skywork_reward_score": 11.346097513834636,
        "CAR_score": 1.78,
        "cos_similarity": 0.7385904947916667
    },
    "winogrande_groundtruth": {
        "perplexity": 64765.68785807292,
        "IDF_score": 514.0,
        "log_propability": -10.6,
        "skywork_reward_score": 11.346097513834636,
        "CAR_score": 0.347,
        "cos_similarity": 0.41842447916666664
    },
    "winogrande_openai_human_written_examples": {
        "perplexity": 6.371827252705892,
        "IDF_score": 0.237,
        "log_propability": -123.0,
        "skywork_reward_score": 11.346097513834636,
        "CAR_score": 1.8,
        "cos_similarity": 0.7438639322916667
    }
}