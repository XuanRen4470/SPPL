{
    "gsm8k_step_by_step": {
        "perplexity": 1.9024011373519898,
        "IDF_score": 0.569,
        "log_propability": -128.0,
        "skywork_reward_score": 12.408854166666666,
        "CAR_score": 4.29
    },
    "gsm8k_claude": {
        "perplexity": 1.8237927953402202,
        "IDF_score": 0.442,
        "log_propability": -73.3,
        "skywork_reward_score": 15.889583333333333,
        "CAR_score": 5.72
    },
    "gsm8k_gpt4_style_in_context_examples": {
        "perplexity": 2.1735092957814532,
        "IDF_score": 0.554,
        "log_propability": -114.0,
        "skywork_reward_score": 7.341796875,
        "CAR_score": 2.25
    },
    "gsm8k_gpt4": {
        "perplexity": 1.972957928975423,
        "IDF_score": 0.519,
        "log_propability": -99.0,
        "skywork_reward_score": 12.632291666666667,
        "CAR_score": 4.24
    },
    "gsm8k_mini_gpt4": {
        "perplexity": 2.0302068114280702,
        "IDF_score": 0.529,
        "log_propability": -105.0,
        "skywork_reward_score": 12.832291666666666,
        "CAR_score": 4.17
    },
    "gsm8k_groundtruth": {
        "perplexity": 3.2275047063827516,
        "IDF_score": 0.614,
        "log_propability": -101.0,
        "skywork_reward_score": 2.9813802083333334,
        "CAR_score": 0.683
    },
    "gsm8k_openai_human_written_examples": {
        "perplexity": 2.2520397106806436,
        "IDF_score": 0.537,
        "log_propability": -109.0,
        "skywork_reward_score": 7.156510416666666,
        "CAR_score": 2.15
    },
    "gsm8k_rewrite_groundtruth_in_own_words": {
        "perplexity": 3.6368122577667235,
        "IDF_score": 0.682,
        "log_propability": -165.0,
        "skywork_reward_score": -1.7171875,
        "CAR_score": -0.358
    }
}