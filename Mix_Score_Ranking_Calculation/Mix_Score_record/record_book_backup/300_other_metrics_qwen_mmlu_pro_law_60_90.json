{
    "mmlu_pro_law_step_by_step": {
        "perplexity": 4.002099704742432,
        "IDF_score": 0.746,
        "log_propability": -517.0,
        "skywork_reward_score": 12.7771484375,
        "CAR_score": 2.52
    },
    "mmlu_pro_law_claude": {
        "perplexity": 2.8211085637410482,
        "IDF_score": 0.63,
        "log_propability": -258.0,
        "skywork_reward_score": 11.332291666666666,
        "CAR_score": 2.78
    },
    "mmlu_pro_law_gpt4_style_in_context_examples": {
        "perplexity": 4.0420404752095545,
        "IDF_score": 0.712,
        "log_propability": -379.0,
        "skywork_reward_score": 12.565234375,
        "CAR_score": 2.47
    },
    "mmlu_pro_law_gpt4": {
        "perplexity": 4.087982408205668,
        "IDF_score": 0.716,
        "log_propability": -392.0,
        "skywork_reward_score": 8.871378580729166,
        "CAR_score": 1.72
    },
    "mmlu_pro_law_mini_gpt4": {
        "perplexity": 3.479914689064026,
        "IDF_score": 0.622,
        "log_propability": -265.0,
        "skywork_reward_score": 6.098697916666667,
        "CAR_score": 1.3
    },
    "mmlu_pro_law_groundtruth": {
        "perplexity": 5148.761832682291,
        "IDF_score": 1.91,
        "log_propability": -30.5,
        "skywork_reward_score": -13.538541666666667,
        "CAR_score": -0.566
    },
    "mmlu_pro_law_openai_human_written_examples": {
        "perplexity": 4.62359987894694,
        "IDF_score": 0.665,
        "log_propability": -225.0,
        "skywork_reward_score": 6.651692708333333,
        "CAR_score": 1.23
    }
}