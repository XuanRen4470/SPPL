{
    "plan_bench_generation_step_by_step": {
        "perplexity": 2.187220537662506,
        "IDF_score": 0.666,
        "log_propability": -314.0,
        "skywork_reward_score": 1.3635660807291667,
        "CAR_score": 0.42
    },
    "plan_bench_generation_claude": {
        "perplexity": 2.192414903640747,
        "IDF_score": 0.597,
        "log_propability": -162.0,
        "skywork_reward_score": -2.1416015625,
        "CAR_score": -0.644
    },
    "plan_bench_generation_gpt4_style_in_context_examples": {
        "perplexity": 2.199174483617147,
        "IDF_score": 0.648,
        "log_propability": -300.0,
        "skywork_reward_score": 0.8552897135416667,
        "CAR_score": 0.259
    },
    "plan_bench_generation_gpt4": {
        "perplexity": 2.515436311562856,
        "IDF_score": 0.671,
        "log_propability": -316.0,
        "skywork_reward_score": -0.7999348958333333,
        "CAR_score": -0.216
    },
    "plan_bench_generation_mini_gpt4": {
        "perplexity": 2.8404507358868916,
        "IDF_score": 0.686,
        "log_propability": -331.0,
        "skywork_reward_score": -6.207332356770833,
        "CAR_score": -1.53
    },
    "plan_bench_generation_groundtruth": {
        "perplexity": 15.394672473271688,
        "IDF_score": 0.612,
        "log_propability": -68.2,
        "skywork_reward_score": -12.202083333333333,
        "CAR_score": -1.68
    },
    "plan_bench_generation_openai_human_written_examples": {
        "perplexity": 2.7001948714256288,
        "IDF_score": 0.662,
        "log_propability": -283.0,
        "skywork_reward_score": -0.8657552083333333,
        "CAR_score": -0.221
    },
    "plan_bench_generation_rewrite_groundtruth_in_own_words": {
        "perplexity": 2.8159676790237427,
        "IDF_score": 0.691,
        "log_propability": -184.0,
        "skywork_reward_score": -7.963802083333333,
        "CAR_score": -1.99
    }
}