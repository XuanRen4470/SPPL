{
    "drop_step_by_step": {
        "perplexity": 3.4129462361335756,
        "IDF_score": 0.726,
        "log_propability": -199.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.04,
        "cos_similarity": 0.739287109375
    },
    "drop_claude": {
        "perplexity": 3.006569905281067,
        "IDF_score": 0.576,
        "log_propability": -129.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.11,
        "cos_similarity": 0.7818603515625
    },
    "drop_gpt4_style_in_context_examples": {
        "perplexity": 3.229872351884842,
        "IDF_score": 0.664,
        "log_propability": -158.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.06,
        "cos_similarity": 0.77861328125
    },
    "drop_gpt4": {
        "perplexity": 3.535870611667633,
        "IDF_score": 0.62,
        "log_propability": -166.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.04,
        "cos_similarity": 0.7796533203125
    },
    "drop_mini_gpt4": {
        "perplexity": 3.4796517658233643,
        "IDF_score": 0.602,
        "log_propability": -163.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.05,
        "cos_similarity": 0.7892724609375
    },
    "drop_groundtruth": {
        "perplexity": 576.0015262615681,
        "IDF_score": 6.96,
        "log_propability": -28.1,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 0.36,
        "cos_similarity": 0.40434326171875
    },
    "drop_openai_human_written_examples": {
        "perplexity": 3.051269371509552,
        "IDF_score": 0.508,
        "log_propability": -112.0,
        "skywork_reward_score": 4.677765299479167,
        "CAR_score": 1.13,
        "cos_similarity": 0.796806640625
    }
}