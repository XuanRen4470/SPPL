{
    "squad_step_by_step": {
        "perplexity": 4.680190793673197,
        "IDF_score": 0.724,
        "log_propability": -243.0,
        "skywork_reward_score": 3.81082275390625,
        "CAR_score": 0.717,
        "cos_similarity": 0.62392578125
    },
    "squad_claude": {
        "perplexity": 3.2311200380325316,
        "IDF_score": 0.58,
        "log_propability": -185.0,
        "skywork_reward_score": 3.81082275390625,
        "CAR_score": 0.862,
        "cos_similarity": 0.7156778971354166
    },
    "squad_gpt4_style_in_context_examples": {
        "perplexity": 3.956493337949117,
        "IDF_score": 0.758,
        "log_propability": -241.0,
        "skywork_reward_score": 3.81082275390625,
        "CAR_score": 0.752,
        "cos_similarity": 0.6339518229166666
    },
    "squad_gpt4": {
        "perplexity": 6.427075791358948,
        "IDF_score": 0.676,
        "log_propability": -178.0,
        "skywork_reward_score": 3.81082275390625,
        "CAR_score": 0.625,
        "cos_similarity": 0.7574462890625
    },
    "squad_mini_gpt4": {
        "perplexity": 5.281687474250793,
        "IDF_score": 0.567,
        "log_propability": -140.0,
        "skywork_reward_score": 3.81082275390625,
        "CAR_score": 0.682,
        "cos_similarity": 0.7597737630208333
    },
    "squad_groundtruth": {
        "perplexity": 134.61884623765945,
        "IDF_score": 0.0758,
        "log_propability": -13.3,
        "skywork_reward_score": 3.81082275390625,
        "CAR_score": 0.501,
        "cos_similarity": 0.36291097005208334
    },
    "squad_openai_human_written_examples": {
        "perplexity": 3.282389295101166,
        "IDF_score": 0.288,
        "log_propability": -74.2,
        "skywork_reward_score": 3.81082275390625,
        "CAR_score": 0.871,
        "cos_similarity": 0.7463785807291666
    }
}