{
    "mmlu_moral_scenarios_step_by_step": {
        "perplexity": 3.2067508792877195,
        "diversity_score": 0.0137,
        "complexity_score": 0.00758,
        "IDF_score": 0.522,
        "average_token_len": 232.26,
        "Average_Char_Lenth": 1107.94
    },
    "mmlu_moral_scenarios_gpt4": {
        "perplexity": 3.1806587505340578,
        "diversity_score": 0.0118,
        "complexity_score": 0.00759,
        "IDF_score": 0.379,
        "average_token_len": 149.2,
        "Average_Char_Lenth": 758.46
    },
    "mmlu_moral_scenarios_claude": {
        "perplexity": 2.4928347277641296,
        "diversity_score": 0.00983,
        "complexity_score": 0.00694,
        "IDF_score": 0.39,
        "average_token_len": 161.98,
        "Average_Char_Lenth": 811.98
    },
    "mmlu_moral_scenarios_mini_gpt4": {
        "perplexity": 2.9104784059524538,
        "diversity_score": 0.0119,
        "complexity_score": 0.00647,
        "IDF_score": 0.354,
        "average_token_len": 138.46,
        "Average_Char_Lenth": 690.94
    },
    "mmlu_moral_scenarios_groundtruth": {
        "perplexity": 919.8447290039062,
        "diversity_score": 0.134,
        "complexity_score": 0.00214,
        "IDF_score": 28.6,
        "average_token_len": 4.0,
        "Average_Char_Lenth": 15.0
    },
    "mmlu_moral_scenarios_gpt4_style_in_context_examples": {
        "perplexity": 2.9920650577545165,
        "diversity_score": 0.011,
        "complexity_score": 0.00607,
        "IDF_score": 0.474,
        "average_token_len": 215.56,
        "Average_Char_Lenth": 1035.84
    },
    "mmlu_moral_scenarios_openai_human_written_examples": {
        "perplexity": 3.7566570615768433,
        "diversity_score": 0.0185,
        "complexity_score": 0.00904,
        "IDF_score": 0.274,
        "average_token_len": 96.8,
        "Average_Char_Lenth": 484.84
    }
}